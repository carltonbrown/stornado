# PrepWorker
# It has a handle to the ready queue, processing queue, and parent upload dir
# PROCESSING DIR IS DISTINCT FROM UPLOAD DIR
# It asks the ready queue for the next .msg.json
# When it finds one, it parses into a Request, adding the source file as a field of the Request
# Then it splits the file into the upload dir.   
# It also writes the Request itself into the parent_upload/$backname dir
# Immediately following, it scans upload dir and adds those paths to the Request
# Then it dequeues the Request from ready queue and places it in the processing queue
DONE

# TransferWorker
# It has a handle to the processing queue and the done queue
# It asks the processor queue for the next msg.json
# For each part, it checks if the part is on the filesystem. 
  # If not, it checks the store to ensure it is uploaded.   Otherwise, this is an exception.
  # Otherwise, it uploads the part, verifies the upload, and deletes the part
# When all parts are uploaded, it dequeues message from processing and places it in 'done' with a status

#TODO
* The parts and their md5sum should be put into the message.
* The split dir should be a directory queue.
* The message itself should get uploaded.
* It's got no configging/environment (how does it get its container info, its account info, where to find the space?)
  * The location of the space - should come from an attribute
  * The stornado repo is contained in the message.
  * The stornado config should be written by what - the backup cookbook?
* How do we launch it? 
   * Upstart?
* Rethink the storage schema
* It's got no alerting.  It doesn't status the caller
  ** Ask Karl what to do.

# DOING
* cookbook sodev_backup exists but has nothing in it
* Test failure case
  * Crash should not kill the whole daemon
  * It should catch the exception, append status to the message, move message to done.

#  KIND OF DONE
* It's got logging
  ** Use the syslog module
* It's got no sample client
   * Genmsg is kind of a sample client
* Baknado now goes in the stornado gem. 
